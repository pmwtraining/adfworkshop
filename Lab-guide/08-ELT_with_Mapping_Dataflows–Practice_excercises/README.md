![](.//media/image1.png)

ELT with Mapping Dataflows – Practice excercises

Dataflow ELT for FoodDim and FoodNutrientsDim

# Contents

[ELT with Mapping Dataflows 1](#elt-with-mapping-dataflows)

[Task 1: Create Data warehouse tables for SmartFoods in Azure SQLDB
1](#create-data-warehouse-tables-for-smartfoods-in-azure-sqldb)

[Task 2: Practice exercise – Create Dataflow ELT for FoodDim
5](#practice-exercise-create-dataflow-elt-for-fooddim)

[Task 3: Create Dataflow ELT for foodNutrientsDim
18](#create-dataflow-elt-for-foodnutrientsdim)

# ELT with Mapping Dataflows

#### Create Data warehouse tables for SmartFoods in Azure SQLDB

**If you already completed previous exercise, You can skip creating
tables and schemas and continue to creating the dataflow.**

Here is the initial star schema we are building for SmartFoods DW. Later
we will also introduce some aggregate tables for easier reporting.

![](.//media/image2.png)

Either using Query Editor in Azure Portal or using SSMS connect to your
Azure SQL DB and create a schema for SmartFoods DW and all the tables by
running the following SQL script.

> **Note:** You may need to add your Client IP Address to your SQL DB
> through “Set Firewall” page.

    CREATE SCHEMA SmartFoodsDW;
    GO
    CREATE TABLE [SmartFoodsDW].[customerDim](
    	[CustomerKey] [bigint],
    	[LoyaltyNum] [nvarchar](max),
    	[FirstName] [nvarchar](max) NULL,
    	[LastName] [nvarchar](max) NULL,
    	[City] [nvarchar](max) NULL,
    	[State] [nvarchar](max) NULL,
    	[Email] [nvarchar](max) NULL,
    	[Address] [nvarchar](max) NULL,
    	[PostCode] [nvarchar](max) NULL,
    	[MemberSince] [date] NULL,
    	[Dob] [date] NULL,
    	[RecInsertDt] [date] NULL,
    	[RecStartDt] [date] NULL,
    	[RecEndDt] [date] NULL,
    	[RecCurrInd] [bit] NULL,
    	[sourceLineage] [nvarchar](max),
    	[RecMd5Hash] [nvarchar](max) 
    ) ;
    GO
    CREATE TABLE [SmartFoodsDW].[foodDim](
    	[sku] [nvarchar](max),
    	[foodKey] [bigint],
    	[desc] [nvarchar](max) NULL,
    	[foodGroup] [nvarchar](max) NULL,
    	[RecInsertDt] [date] NULL,
    	[RecStartDt] [date] NULL,
    	[RecEndDt] [date] NULL,
    	[RecCurrInd] [bit] NULL,
    	[sourceLineage] [nvarchar](max),
    	[RecMd5Hash] [nvarchar](max) 
    ) ;
    GO
    CREATE TABLE [SmartFoodsDW].[foodNutDim](
    	[foodKey] [bigint],
    	[nutrientId] [nvarchar](max),
    	[nutritionValue] [float] NULL,
    	[desc] [nvarchar](max) NULL,
    	[nutUnit] [nvarchar](60) NULL,
    	[RecInsertDt] [date] NULL
    );
    GO
    
    CREATE TABLE [SmartFoodsDW].[invoiceLineTxn](
    	[invoiceNumber] [nvarchar](max),
    	[lineNumber] [int],
    	[foodKey] [bigint],
    	[itemDesc] [nvarchar](max) NULL,
    	[itemFoodGroup] [nvarchar](max) NULL,
    	[uPrice] [float],
    	[qty] [bigint],
    	[gst] [float],
    	[lineTotalGstExc] [float],
    	[lineTotalGstInc] [float],
    	[sourceLineage] [nvarchar](max),
    	[recInsertDt] [date] 
    );
    GO
    CREATE TABLE [SmartFoodsDW].[invoiceTxn](
    	[invoiceNumber] [nvarchar](max),
    	[loyaltyNum] [nvarchar](max) NULL,
    	[CustomerKey] [bigint] NULL,
    	[store] [nvarchar](max) NULL,
    	[State] [nvarchar](max) NULL,
    	[lineItemCount] [bigint],
    	[invoiceTotalGSTinc] [float],
    	[invoiceTotalGSTexc] [float],
    	[InvoiceGst] [float],
    	[timestamp] [datetime2](7),
    	[sourceFileLineage] [nvarchar](max),
    	[recInsertDt] [date] 
    ) ;
    GO

####   
Practice exercise – Create Dataflow ELT for FoodDim

> **Note:** This is an practice exercise and as such there is minimal
> instructions. The dataflow follows the same pattern as previous part.
> If you don’t feel confident about any part of this exercise refer to
> the previous part for full explanations.

Below is the schema of foodDim table:

|                       |           |        |             |             |            |          |            |               |            |
| --------------------- | --------- | ------ | ----------- | ----------- | ---------- | -------- | ---------- | ------------- | ---------- |
| Sku\* -\> Natural key | Foodkey\* | Desc\* | Foodgroup\* | RecInsertDt | RecStartDt | RecEndDt | RecCurrInd | sourceLineage | RecMd5Hash |

> Columns marked with \* are available in source dataset and the rest
> will be generated by the ELT process.

1.  Create a new Mapping DF rename it to “*SmartFoodFoodELT*”

2.  Create two Dataflow parameters as “MaxSurrogateKey” and “BatchDt”

![](.//media/image3.png)

3.  Add Source transform and rename it to “*SmartFoodsFoodStagingBlob*”
    
    1.  Set it up using Screenshots as guide

> ![](.//media/image4.png)
> 
> ![](.//media/image5.png)

4.  Go to debug settings and fill in the parameters

> ![](.//media/image6.png)
> 
> ![](.//media/image7.png)

5.  In source transform run “Import projection”

> ![](.//media/image8.png)

6.  Add “Select” transform and rename it to “FixColumnNames”

7.  Set it up using screenshots as guide:

![](.//media/image9.png)

8.  Add “Derived column” Transform to calculated MD5 and rename it to
    “*MD5Hash*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image10.png)

    iif(isNull(ifoodGroup),'',toString(ifoodGroup)))

9.  Add a second “Source” transform to connect to DW table and rename it
    to “*SmartFoodsFoodSQLDW*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image11.png)

10. Fill in the dataset parameters in debug settings

![](.//media/image12.png)

11. Import projection for new data source

![](.//media/image13.png)

12. Add filter transform after DW source to filter active records only
    and rename it to “FilterCurrentRows”
    
    1.  Set it up using screenshots as guide:

![](.//media/image14.png)

13. After MD5Hash transform add “Join” transform and rename it to
    “*JoinStagingToDWDim*”
    
    1.  Set it up using screenshots as guide

![](.//media/image15.png)

14. Add a “Conditional Split” transform and rename it to “*SDC2Split*”
    
    1.  Set it up using the screenshot as a guide

![](.//media/image16.png)

15. After “Changed” stream add a “New branch” transform

16. Add a “Select” transform after one of the branches and rename it to
    “*SelectChangedUpdate*”

![](.//media/image17.png)

1.  Set it up using screenshot as guide

> ![](.//media/image18.png)

17. After “SelectChangeUpdate” add a “Derived column” transform and
    rename it to “*UpdateRecsBatchColumns*”
    
    1.  Set it up

![](.//media/image19.png)

18. After the other stream of “new branch” add a “Select” transform and
    rename it to “*SelectChangedInsert*”

![](.//media/image20.png)

1.  Set it up using screenshot as guide:

![](.//media/image21.png)

19. After the “New” stream of “Conditional Split” add “select” transform
    rename it to “SelectNewInsert”

![](.//media/image22.png)

1.  Set it up using screenshot as a guide:

![](.//media/image23.png)

20. Add a “Union” transform after “SelectNewInsert” and rename it to
    “AllInserts”
    
    1.  Set it up using screenshot as a guide:

![](.//media/image24.png)

21. Add “Surrogate Key” transform and rename it to “SurrogateKey”
    
    1.  Set it up using screenshot as a guide:

![](.//media/image25.png)

22. Add “Derived Column” transform to update the surrogate key with
    maximum SK and rename it to “AddMaxFoodKey”
    
    1.  Set it up using screenshot as guide:

![](.//media/image26.png)

23. Add another “Derived column” transform to generate batch columns and
    rename it to “*InsertRecsBatchColumns*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image27.png)

24. Add “Union” transform to put updates and inserts together. Rename it
    to “*UnionInsertUpdates*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image28.png)

25. Add an “Alter Row” transform to mark each row with the type of DB
    action. Rename it to “*MarkRow*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image29.png)

26. Finally add “Sink” transform and rename it to “*FoodDim*”
    
    1.  Set it up using screenshots as guide:

![](.//media/image30.png)

![](.//media/image31.png)

27. Your flow should now look like this:

![](.//media/image32.png)

28. Validate and publish your flow.

#### Create Dataflow ELT for foodNutrientsDim

The next dimension we need to create is for food-nutrients and for
practicing purpose, we are building this dimension as slowly changing
dimension type 1 (This method overwrites old with new data, and
therefore does not track historical data.). As this method overwrites
the data the ELT dataflow is much simpler.

Also, the other thing to note is we are combining two source files to
build this dimension. 1. Food\_nut.csv and 2. NutDim.csv. As the
relationship between food and nutrients is a many-to-many the source
system provided the full 3<sup>rd</sup> normal form which needs to be
transformed into dimensional start schema.

The schema for for FoodNutDim is as below:

|                             |              |                  |        |           |             |
| --------------------------- | ------------ | ---------------- | ------ | --------- | ----------- |
| foodKey -\> SK from foodDim | nutrientId\* | nutritionValue\* | Desc\* | nutUnit\* | RecInsertDt |

> Columns marked with \* are available in source dataset and the rest
> will be generated by the ELT process.

1.  Create a new Mapping dataflow and rename it to
    “*SmartFoodFoodNutritionELT*”

![](.//media/image33.png)

2.  Create a parameter named “BatchDt”

![](.//media/image34.png)

3.  Add a “Source” transform and rename it to
    “*SmartFoodsFoodNutrientsStagingBlob*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image35.png)

4.  Add a second “Source” transform and rename it to
    “*SmartFoodsNutrientsStaging*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image36.png)

5.  Add a thirds “Source” transform and rename it to
    “*SmartFoodsFoodSQLDW*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image37.png)

6.  Go to Debug settings and fill in all dataset parameters:

![](.//media/image38.png)

![](.//media/image39.png)

7.  Run “Import projection” on all three “source” transforms:

Make sure for the data types match the below screenshots.

![](.//media/image40.png)

![](.//media/image41.png)

![](.//media/image42.png)

8.  After “*SmartFoodsFoodSQLDW*” transform add a “Filter” transform and
    rename it to “*CurrentRecsOnly*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image43.png)

9.  After “SmartFoodsFoodNutrientsStagingBlob” transform add a “Filter”
    transform and rename it to “*FilterZeroNutrients*”

> Source dataset has a record for every nutrient for every food, even if
> that food dose not contain that nutrient. As such we need to remove
> those nutrients with value equals to zero from our dataset.

1.  Set it up using screenshot as guide:

![](.//media/image44.png)

10. Add a “Select” transform and rename it to “*FixColumnNames*”
    
    1.  Set it up using screenshot as guide:

![](.//media/image45.png)

11. Add “Join” transform and rename it to “*JoinStagingToDWDim*”

![](.//media/image46.png)

12. Add another “Join” transform and rename it to “*JoinNutrients*”.

> The right-hand side of the join is “SmartFoodsNutrientsStaging”

![](.//media/image47.png)

13. Add “Select” transform and rename it to “*removeExtraCols*”

![](.//media/image48.png)

14. Add a “Derived” column transform and rename it to
    “*InsertRecsBatchColumns*”

![](.//media/image49.png)

15. Add a “Sink” transform and rename it to “*DBSink*”

![](.//media/image50.png)

![](.//media/image51.png)

> **Note1:** As this is a truncate-load pattern we changed the table
> action to “Truncate table”
> 
> **Note2:** Sink transform in this dataflow will only perform
> **inserts** and as such there is **NO NEED** for an “Alter Row”
> transform.

16. Your final dataflow should look like this:

![](.//media/image52.png)
